=================
Entrenamiento
=================

Repositorio: `CustumObjectDetection <https://github.com/Daegas/CustumObjectDetection>`_ 


Contexto
========
El fin de esta secci√≥n es compilar informaci√≥n b√°sica para entender el proceso
de entrenamiento del modelo.

Redes Neuronales Convolucionales (CNN)
----------------------------------------
Las CNN fueron introducidas por primera vez por Yann LeCun 1998 en 
`Gradient-Based Learning Applied to Document Recognition <https://pdfs.semanticscholar.org/62d7/9ced441a6c78dfd161fb472c5769791192f6.pdf>`_
y resultaron ser muy efectivas en reconocimiento de im√°genes y clasificaci√≥n.

üëÅ `¬øPero qu√© "es" una Red neuronal? <https://www.youtube.com/watch?v=aircAruvnKk>`_

C√≥mo se ve en el video una red neuronal est√° compuesta por capas, cada capa contiene un vector de
caracter√≠sticas que conservan una relaci√≥n espacial entre pixeles.
Dada una imagen en forma de matriz:


* Se aplican filtros para resaltar bordes, circunferencias, esquinas, etc. Esta t√©cnica para detectar las partes m√°s importantes de una imagen se llama "convoluci√≥n" 
    üëÅ `Explicaci√≥n Visual <https://setosa.io/ev/image-kernels/>`_
* Con el descenso de gradiente se buscar calcular cuales valores de pesos y bias minimizan el costo, la distancia del resultado obtenido en la √∫ltima capa con el resultado esperado.
    üëÅ `Descenso de gradiente, es como las redes neuronales aprenden <https://www.youtube.com/watch?v=IHZwWFHWa-w&t=660s>`_
* Cada neurona en la pen√∫ltima capa necesita unos ajustes de par√°metros (bias, pesos) para que en la √∫ltima capa (salida) las neuronas m√°s activas correspondan a las que se esperan est√©n m√°s activas. Se agregan todos los ajustes de todas las neuronas de esa pen√∫ltima capa, luego se hace lo mismo con la antepen√∫ltima y as√≠ hasta llegar a la segunda capa (la primera es la entrada). A eso se le llama "retropropagaci√≥n".
    üëÅ `¬øQu√© es la retropropagaci√≥n y qu√© hace en realidad? <https://www.youtube.com/watch?v=Ilg3gGewQ5U>`_

Otros datos:


* Cada neurona toma la una entrada, la multiplica por el peso, le agrega el bias y el resultado lo pasa por una funci√≥n de activaci√≥n, que son funciones que determinan si una neurona debe o no ser activada. Ayudan a normalizar en un rango [0 , 1] o [-1 , 1] Existen muchos tipos de funciones de activaci√≥n (Sigmoid, ReLU, TanH, LeakyReLU, Softmax, etc)
    üëÅ `Funciones de Activaci√≥n <https://www.i2tutorials.com/activation-functions-in-deep-learning/>`_
* El prop√≥sito de cada capa varia, a veces pueder ser reducir dimensionalidad (pooling), detectar patrones (convoluci√≥n) entre otras funciones.
* Existen muchas arquitecturas, es decir cuantas capas, de que tipo y en que acomodo se usan en una red. Hay arquitecturas de redes neuronales que no tienen convoluci√≥n, generalmente las usadas en reconocimiento y clasificaci√≥n de im√°genes si tienen. Algunas arquitecturas muy famosas de CNN especiales para detectar patrones visuales son VGG, Inception, RESNET.
    üëÅ `Arquitecturas <https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5>`_

üëÅ `Ejemplo visual, reconocimiento de d√≠gitos <https://www.cs.cmu.edu/~aharley/vis/conv/flat.html>`_

Detecci√≥n de Objetos
---------------------
De acuero con `wikypedia <√Årea relacionada con la visi√≥n artificial y el procesamiento de imagen que trata de detectar casos de objetos sem√°nticos de una cierta clase (como humanos, edificios, o coches) en v√≠deos e im√°genes digitales.‚Äã>`_
la detecci√≥n de objetos es: √Årea relacionada con la visi√≥n artificial y el procesamiento de imagen que trata de detectar casos de objetos sem√°nticos de una cierta clase (como humanos, edificios, o coches) en v√≠deos e im√°genes digitales.‚Äã
Es diferente un problema de clasificaci√≥n c√≥mo:


.. figure:: img/fiat.jpg
    :width: 200px
    :align: center    

[#f1]_

Donde es una sola clase, a un problema de reconocimiento y clasificaci√≥n como:

.. figure:: img/or.png
    :width: 200px
    :align: left 

.. figure:: img/or1.png
    :width: 200px
    :align: center  

Que son varias instancias de varias clases en una sola im√°gen.



   
¬øC√≥mo se implementan?
---------------------------

pff

Instalaci√≥n
===========

Brief Summary
-------------

Last updated: 6/22/2019 with TensorFlow v1.13.1. 

Mainly based on
`EdjeElectronics <https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10>`_'s
and
`Khaivdo <https://github.com/Khaivdo/How-to-train-an-Object-Detector-using-Tensorflow-API-on-Ubuntu-16.04-GPU>`__'s
repositories. This repository attempts to make it work with specific
Tensorflow CPU version 1.7 and its corresponding API*

1. Install Anaconda
-------------------

*Is useful for version management*

Install the previous requirements:

::

    sudo apt-get install libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6 -y

Get the installation .sh file by running this commands:

::

    cd  ~/Desktop
    wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh
    chmod +x Anaconda3-2020.02-Linux-x86_64.sh 

Execute it:

::

    sh Anaconda3-2020.02-Linux-x86_64.sh -y

And if you pleased delete the it:

::

    rm Anaconda3-2020.02-Linux-x86_64.sh

2. Create and set your environment
----------------------------------

Open a new terminal and it should appear (base) before your user name.

*I case it doesn't, run this commands:* :sub:`~` eval
"$(/home//anaconda3/bin/conda shell.bash hook) conda init :sub:`~` *In
case you use a different shell, replace shell.bash for shell.<
YourShell>*

Download the spec-list\_tf-cpu.txt file
`here <https://ugtomx-my.sharepoint.com/:f:/g/personal/de_gamasandoval_ugto_mx/EpCz_C7gow5Ai7OjD9TBcoABi6aGlIjGSsUvc4n5Gj3mdA?e=VbZKWV>`__:
Now let's create and activate our environment: :sub:`~` conda create
--name tf-cpu --file ~/Downloads/spec-list\_tf-cpu.txt conda activate
tf-cpu :sub:`~` Install this dependecies: :sub:`~` pip install Cython
pip install contextlib2 pip install pillow pip install lxml pip install
jupyter pip install matplotlib pip install pandas pip install
opencv-python pip install
"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI"
:sub:`~` Install tensorflow version 1.7 :sub:`~` pip install
tensorflow==1.7 :sub:`~` *You can propably use another version but some
lines of code might change, and you'll need to find its corresponding
API version*

3. Download repositories
------------------------

First create a directory on your Desktop :sub:`~` cd ~/Desktop mkdir
ObjectDetection :sub:`~` ### 3.3 `This
Repository <https://github.com/Daegas/CustumObjectDetection>`__

3.2 `Tensorflow Object Detection API <https://github.com/tensorflow/models>`__
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

There are several branches of the API they are targeted to different
tensorflow versions, since we installed version 1.7,
`here <https://github.com/tensorflow/models/tree/adfd5a3aca41638aa9fb297c5095f33d64446d8f>`__
is the corresponding branch. You have two option for download it: -
Directly from github (Click on Clone or Download button) and then
extract it on your ~/Desktop/ObjectDetection directory. - Or you can try
with these commands, which I saw works properly :sub:`~` cd
~/Desktop/ObjectDetection git clone https://github.com/tensorflow/models
cd models git reset --hard adfd5a3aca41638aa9fb297c5095f33d64446d8f
:sub:`~` *You basically download the current repository and then reset
to an old commit with its sha.*

3.3 `Model Zoo <https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md>`__
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You can find a list of models, download and extract into
PretrainedModels. Here will use
`ssd\_inception\_v2\_coco <http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz>`__
Finally this is how ObjectDetection should look

::

                                                    ADD IMAGE

4. Compile Protobufs
--------------------

Protobuf is a way to share data among applications, a little bit like
what JSON does. Is used by tensorflow to configure models and training
parameters and is implemented for several languages. So we need to
compile it for python. :sub:`~` cd
~/Desktop/ObjectDetection/models/research protoc
object\_detection/protos/\*.proto --python\_out=. :sub:`~` This creates
a name\_pb2.py file from every name.proto file in the
/object\_detection/protos folder.

**(Note: TensorFlow occassionally adds new .proto files to the folder.
If you get an error saying ImportError: cannot import name
'something\_something\_pb2' , you may need to update the protoc command
to include the new .proto files.)**

5. PYTHONPATH
-------------

For running, you need to specify where it gathers the data. So add
models/research to your PYTHONPATH. You'll need eat for each new
terminal, you could add it to your .bashrc file which is in /home and
appear by pressing ``Ctrl``\ +\ ``h`` but you'll need to replace the
``pwd`` for the absolute path to models/research.

::

    cd ~/Desktop/ObjectDetection/models/research/
    export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim

6. Test
-------

There are 2 ways to test your installation ### Easy Just run: :sub:`~`
cd ~/Desktop/ObjectDetection/models/research/ python
object\_detection/builders/model\_builder\_tf1\_test.py :sub:`~` Looks
like this: ADD IMAGE

Explained
~~~~~~~~~

::

    cd ~/Desktop/ObjectDetection/models/research/object_detection
    jupyter notebook object_detection_tutorial.ipynb

If it doesn't opens directly the notebook, click on the link that
appears on your terminal and open the notebook
object\_detection\_tutorial.ipynb listed.

::

                                                    ADD IMAGE

*This section is from
`Edje <https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10>`__*

This opens the script in your default web browser and allows you to step
through the code one section at a time. You can step through each
section by clicking the ‚ÄúRun‚Äù button in the upper toolbar. The section
is done running when the ‚ÄúIn [ \* ]‚Äù text next to the section populates
with a number (e.g. ‚ÄúIn [1]‚Äù).

(Note: part of the script downloads the ssd\_mobilenet\_v1 model from
GitHub, which is about 74MB. This means it will take some time to
complete the section, so be patient.)

Once you have stepped all the way through the script, you should see two
labeled images at the bottom section the page. If you see this, then
everything is working properly! If not, the bottom section will report
any errors encountered. See the
`Appendix <https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#appendix-common-errors>`__
for a list of errors I encountered while setting this up.

**Note: If you run the full Jupyter Notebook without getting any errors,
but the labeled pictures still don't appear, try this: go in to
object\_detection/utils/visualization\_utils.py and comment out the
import statements around lines 29 and 30 that include matplotlib. Then,
try re-running the Jupyter notebook.**



.. rubric:: Footnotes

.. [#f1] https://thumbs.dreamstime.com/b/old-fiat-500-1-13471810.jpg