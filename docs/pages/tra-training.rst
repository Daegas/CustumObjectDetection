=================================
Ent/Entrenamiento (Ahora s√≠)
=================================

Repositorio: `CustumObjectDetection <https://github.com/Daegas/CustumObjectDetection>`_ 


1. Generar records de tensorflow
=================================

Basta con correr: 
::

    cd ~/tf-cpu
    python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=data/train.record --image_dir=data/train
    python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=data/test.record  --image_dir=data/test

2. Configurar los archivos de Object Detection
===================================================

``Minuto 8:33 de`` `üéûÔ∏è <https://www.youtube.com/watch?v=0zRsOIp92NQ>`_ .


En el directorio ~/tf-cpu/models/research/object_detection/samples/configs est√°n disponibles los archivos
de configuraci√≥n base para cada modelo. 

Elige el archivo de tu modelo, copialo al directorio ~/tf-cpu/training. Toma en cuenta:

* Reemplazar 'dara' por tu usuaio y 'ssd_inception_v2_coco_2018_01_28' por el nombre del modelo que descargaste.
* Puede que el n√∫mero de l√≠nea no coincida 
* Los puntos 2-5 los puedes encontrar buscando todos los 'PATH_TO_BE_COFIGURED' del archivo

Lo que tienes que modificar:

1. num_classes:1  *L√≠nea 9* En este caso solo es una.
2. fine_tune_checkpoint: "/home/dara/tf-cpu/PretrainedModels/ssd_inception_v2_coco_2018_01_28/model.ckpt"
3. input_path: "/home/dara/tf-cpu/data/train.record  *L√≠nea 169*
4. input_path: "/home/dara/tf-cpu/data/test.record  *L√≠nea 183*
5. label_map_path: "/home/dara/tf-cpu/data/train.record  *L√≠nea 171 y 185*
6. num_examples: 84 *L√≠nea 175* Este n√∫mero debe coincidir con las im√°genes en el directorio data/training.Puede que se agreguen m√°s depu√©s de terminar esta documentaci√≥n, verificar el n√∫mero.

*Opcional* 

7. num_steps: 100000 Esto es el n√∫mero de pasos que se har√°n para el entrenamiento, evidentemente, mientras m√°s pasos, m√°s tiempo, Pero tambi√©n se puede pasar m√°s adelante como argumento.

.. note:: En el directorio ~/tf-cpu/training ya est√° modificado, solo se tendr√≠a que cambiar el nombre de usuario en los PATHS.



3. ¬°A entrenar!
================

Desde tf-cpu:

::

    python models/research/object_detection/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_inception_v2_coco.config

Puedes pasar el n√∫mero de pasos como argumento:

::

    python models/research/object_detection/train.py --logtostderr --train_dir=training/ --num_train_steps=50000 --pipeline_config_path=training/ssd_inception_v2_coco.config

Se ve as√≠, pero en tu caso desde el paso 0 y sin la parte de restaurando parametros:

.. figure:: img/training.jpeg

Puedes detenerlo con ``Ctrl`` + ``c`` y al volver a correr el archivo de entrenamiento, retomar√° en el √∫ltimo checkpoint que encuentre.

4. Tensorboard
===============

``Minuto 34:54 de`` `üéûÔ∏è <https://www.youtube.com/watch?v=0zRsOIp92NQ>`_ .

Se explica un poco mejor en `el repositorio de Khavido <https://github.com/Khaivdo/How-to-train-an-Object-Detector-using-Tensorflow-API-on-Ubuntu-16.04-GPU#32-tensorboard>`_ .

Puedes monitorizar el entrenamieto con tensoarboard. Simplemente en otra terminal corre:

::

    tensorboard --logdir=training

5. Exportar 
===============

Del siguiente comando: 
::

    python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_inception_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-41521 --output_directory trained-inference-graphs/output_inference_graph_v1.pb

Cambiar:

* El nombre del modelo si es necesario
* El n√∫mero del checkpoint m√°s grande que aparezca en un tu directorio ~tf-cpu/training

Aparecer√° el directorio trained-inference-graphs, como se especific√≥ en el comando.

.. note:: 
 En caso de que se haya instalado otra versi√≥n de tensorflow, se recomiendo reemplazar el archivo export_inference_graph.py por el que est√© en /models/research/object_detection.


.. attention:: Aqu√≠ hay algo por investigar, c√≥mo exportar el modelo a formato Keras (h5), pues se almacena con formato de tensorflow (.pb)



`6. Usar el modelo`_
=====================

Ya sea en imagen, video, o c√°mara del video en el archivo revisar:

* MODEL_PATH *L√≠nea 31* Coincida con el existente
* NUM_CLASSES *L√≠nea 40* Sea 1, en este caso.

Para video:

En la *L√≠nea 68* poner el nombre y extensi√≥n del video que debe estar en ~/tf-cpu. Se desacarg√≥ `este video de youtube <https://www.youtube.com/watch?v=XRYusHTtaN0>`_ , est√° disponible `en este enlace <https://ugtomx-my.sharepoint.com/:v:/g/personal/de_gamasandoval_ugto_mx/EdJPz1z1uZpPn4FNys7pwMEBIyhxsACeiOIwrUMMuNz9Ig?e=dg24NX>`_ .

:: 

    python video.py

Para imagen:

En la *L√≠nea 71* poner el nombre de la imgen que debe estar en ~/tf-cpu .

::

    python image.py

Y para c√°mara:

::

    python webcam.py


7. Resultados üì∞
==================
Aqu√≠ se enlistan algunos resultados. Se par√≥ el proceso, pues al ser muy lento el entrenamiento en CPU era muy poco conveniente.

#. Resultados al `paso 41521 / 200000  <https://youtu.be/29_qzIE3WtA>`_ . |step-41521|
#. Resultados al `paso 63324 / 200000  <https://youtu.be/r-SI0KqTpcQ>`_ . |step-63324|

En los videos se muestra, el tensorboard, luego se detiene el proceso de tensorboard y el de entrenamiento,
para exportar y correr el modelo en el video de la secci√≥n  `6. Usar el modelo`_

.. attention:: Estas pruebas son sin las im√°genes  2_27 - 3_178 que se agregaron despu√©s al repositorio.

Orden de Im√°genes:
--------------------

* 0 _ *x*  | Simulaci√≥n Husky, SIN c√°mara, fondo default
* 1 _ *x*  | Simulaci√≥n Husky, CON c√°mara, fondo default
* 2 _ *x*  | Descargadas de internet
* 3 _ *x*  | Simulaciones en el playpen (x< 101) y capturas de pantalla (x>=102).

.. Gr√°ficas de TotalLoss de los pasos:

.. |step-41521| image:: img/step-41521.jpeg
   :scale: 50 %
   :alt: 

.. |step-63324| image:: img/step-63324.jpeg
   :scale: 50 %
   :alt: 





