============================
Contexto
============================


Repositorio: `CustumObjectDetection <https://github.com/Daegas/CustumObjectDetection>`_ 

El fin de esta secci√≥n es compilar informaci√≥n b√°sica para entender el proceso
de entrenamiento del modelo.

Redes Neuronales Convolucionales (CNN)
----------------------------------------
Las CNN fueron introducidas por primera vez por Yann LeCun 1998 en 
`Gradient-Based Learning Applied to Document Recognition <https://pdfs.semanticscholar.org/62d7/9ced441a6c78dfd161fb472c5769791192f6.pdf>`_
y resultaron ser muy efectivas en reconocimiento de im√°genes y clasificaci√≥n.

üëÅ `¬øPero qu√© "es" una Red neuronal? <https://www.youtube.com/watch?v=aircAruvnKk>`_

C√≥mo se ve en el video una red neuronal est√° compuesta por capas, cada capa contiene un vector de
caracter√≠sticas que conservan una relaci√≥n espacial entre pixeles.
Dada una imagen en forma de matriz:


*  üëÅ `Explicaci√≥n Visual Kernels <https://setosa.io/ev/image-kernels/>`_ 



Se aplican filtros para resaltar bordes, circunferencias, esquinas, etc. Esta t√©cnica para detectar las partes m√°s importantes de una imagen se llama "convoluci√≥n"  

* üëÅ `Descenso de gradiente, es como las redes neuronales aprenden <https://www.youtube.com/watch?v=IHZwWFHWa-w&t=660s>`_


Con el descenso de gradiente se buscar calcular cuales valores de pesos y bias minimizan el costo, la distancia del resultado obtenido en la √∫ltima capa con el resultado esperado.

* üëÅ `¬øQu√© es la retropropagaci√≥n y qu√© hace en realidad? <https://www.youtube.com/watch?v=Ilg3gGewQ5U>`_


Cada neurona en la pen√∫ltima capa necesita unos ajustes de par√°metros (bias, pesos) para que en la √∫ltima capa (salida) las neuronas m√°s activas correspondan a las que se esperan est√©n m√°s activas. Se agregan todos los ajustes de todas las neuronas de esa pen√∫ltima capa, luego se hace lo mismo con la antepen√∫ltima y as√≠ hasta llegar a la segunda capa (la primera es la entrada). A eso se le llama "retropropagaci√≥n".

**Otros datos:**


* üëÅ `Funciones de Activaci√≥n <https://www.i2tutorials.com/activation-functions-in-deep-learning/>`_


Cada neurona toma la una entrada, la multiplica por el peso, le agrega el bias y el resultado lo pasa por una funci√≥n de activaci√≥n, que son funciones que determinan si una neurona debe o no ser activada. Ayudan a normalizar en un rango [0 , 1] o [-1 , 1] Existen muchos tipos de funciones de activaci√≥n (Sigmoid, ReLU, TanH, LeakyReLU, Softmax, etc) 

* Capas


El prop√≥sito de cada capa varia, a veces pueder ser reducir dimensionalidad (pooling), detectar patrones (convoluci√≥n) entre otras funciones.

* üëÅ `Arquitecturas <https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5>`_


Existen muchas arquitecturas, es decir cuantas capas, de que tipo y en que acomodo se usan en una red. Hay arquitecturas de redes neuronales que no tienen convoluci√≥n, generalmente las usadas en reconocimiento y clasificaci√≥n de im√°genes si tienen. Algunas arquitecturas muy famosas de CNN especiales para detectar patrones visuales son VGG, Inception, RESNET.

* üëÅ `Aqu√≠ <https://www.cs.cmu.edu/~aharley/vis/conv/flat.html>`_ puedes encontrar un ejemplo interactivo y visual de una CNN para  reconocimiento de d√≠gitos.


.. note::  No te preocupes si no entiendes al 100% todos los links o su teminolog√≠a, pero para los videos se recomienda verlos un par de veces para comprender los conceptos, ya que es la base del aprendizaje.

Detecci√≥n de Objetos
---------------------
De acuero con `wikypedia <√Årea relacionada con la visi√≥n artificial y el procesamiento de imagen que trata de detectar casos de objetos sem√°nticos de una cierta clase (como humanos, edificios, o coches) en v√≠deos e im√°genes digitales.‚Äã>`_
la detecci√≥n de objetos es: √Årea relacionada con la visi√≥n artificial y el procesamiento de imagen que trata de detectar casos de objetos sem√°nticos de una cierta clase (como humanos, edificios, o coches) en v√≠deos e im√°genes digitales.‚Äã

Es diferente un problema de clasificaci√≥n c√≥mo:


.. figure:: img/fiat.jpg
    :width: 200px
    :align: center    

[#f1]_

Donde es una sola clase en toda la imagen; a un problema de reconocimiento y clasificaci√≥n como:

.. figure:: img/or.png
    :width: 200px
    :align: left 

.. figure:: img/or1.png
    :width: 220px
    :align: center  



Que son varias instancias de varias clases en una sola im√°gen. Como podemos ver, para
el segundo ejemplo es necesario definir qu√© objeto se encuentra y que regi√≥n ocupa
dentro de la imagen.
Algunas arquitecturas que se usan para problemas como el segundo ejemplo son:


* Region Based Object Detectors como R-CNN, Fast RCNN, Faster R-CNN, R-FCN, FPN You can learn a bit more üëÅ `here <https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9>`_

Estas usan una ventana que mueven por toda la imagen, esta imagen de la ventana se ajusta a un tama√±o fijo 
y a cada una se le aplica un clasificador. Para reducir el n√∫mero de operaciones, se usan m√©todos
que proponen Regiones de Inter√©s o  *Regions of Interest* (ROIs) o una red completa como *Region Proposal Network*
o RPN, que reducen el n√∫mero de ventanas a analizar,
lo cu√°l se traduce en menor tiempo de entrenamiento. Pero para regi√≥n se hacen *k* propuestas de regi√≥n
por clase. El n√∫mero de operaciones que se hacen sigue siendo elevado.

* üëÅ `Single Shot Detectors como YOLO y SSD <https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d>`_

C√≥mo se explica en el link, estas arquitecturas calculan al mismo tiempo un *boundary box* y la clase. Estos resultan ser buenos en procesamiento en tiempo real, pero tienenalgunos problemas
para detectar objetos o muy cercanos o muy lejanos.


Uno de los grandes problemas en detecci√≥n de objetos y en general de Machine Learning,
es la selecci√≥n del modelo. Esto se resuleve muchas veces de manera emp√≠rica o por
prueba y error. Vamos a tratar de implementar YOLO y SSD, sin dejar de tomar como opciones
otras arquitecturas.


Documentaci√≥n YOLO y SSD:

* `P√°gina oficial YOLO <https://pjreddie.com/darknet/yolo/>`_

* `Art√≠culo YOLO <https://arxiv.org/abs/1506.02640>`_

* `Art√≠culo SSD <https://arxiv.org/abs/1512.02325v5>`_

   
¬øC√≥mo se implementan?
---------------------------
Primero debemos configurar nuestro ambiente de desarrollo. C√≥mo se explic√≥ en la Introducci√≥n este fue
implentado en Ubuntu 18.04. Lo que ocupamos:

* `Anaconda <https://www.anaconda.com/>`_ : Aunque no es totalmente necesaria, es s√∫per √∫til para crear ambientes con diferentes especificaciones. Adem√°s tiene otras herremientas √∫tiles para trabajar. Una alternativa es pipenv. 

* `Tensorflow <https://www.tensorflow.org/>`_ Es una plataforma que contiene herramientas, librer√≠as y recursos que permiten a los desarrolladores introducirse al estado del arte en Machine Learning.‚Äã La implementaci√≥n de arquitecturas de redes neuronales es relativamente f√°cil. ‚ÄãCon 3 l√≠neas de c√≥digo es posible agregar capas. Basta con cambiar las entradas (placeholders) para usar en otras aplicaciones.‚Äã

* `Keras <https://keras.io/>`_  es un API de alto nivel escrita en python para redes neuronales, permite trabajar por encima de Tensorflow. Ideal para hacer prototipos f√°ciles y r√°pidos.‚Äã Usa el backend de tensorflow y tiene ya implementadas capas que son comunes en muchas arquitecturas‚Äã



Es recomendable tener una tarjeta gr√°fica para el entrenamiento. 
Aunque se puede usar solo CPU, los tiempos de entrenamiento aumentan muy considerablemente.

Tensorflow tiene soporte para CPU y GPU, es mil vices m√°s recomendable GPU, para la instalaci√≥n 
de cualquiera de los dos se puede hacer por comandos pip o usando una imagen de docker. Nuevamente lo ideal
y en teor√≠a m√°s sencillo es con una imagen de docker, pues solo se tienen que instalar los drivers manualmente.





.. rubric:: Footnotes

.. [#f1] https://thumbs.dreamstime.com/b/old-fiat-500-1-13471810.jpg